{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logistic_regression as lg\n",
    "import optimizers as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(X.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.04557281469366"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, w[:X.shape[1]]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La régression logistique\n",
    "\n",
    "- Méthode introduite par les statisticiens vers la fin des années 60 et popularisée par Andersen (1982).\n",
    "- Permet de s'affranchir des hypothèses restrictives associées aux méthode linéaires paramétriques.\n",
    "- Hypothèse:\n",
    "    - Logarithme des rapports de probabilités conditionnelles des classes pour une entrée $x$ est linéaire par rapport à $x$.\n",
    "\n",
    "$$\\ln{\\Big(\\frac{\\mathbb{P}(X =x | Y = 1)}{\\mathbb{P}(X = x | Y = -1)}\\Big)} = w_0 + \\langle \\bar{w}, x \\rangle$$\n",
    "\n",
    "\n",
    "- La probabilité à posteriori:\n",
    "\n",
    "$$\\mathbb{P}(Y = 1 | X = x) = \\frac{1}{1 + e^{-(\\tilde{w} + \\langle \\bar{w}, x \\rangle)}}$$\n",
    "\n",
    "Ci-dessous se trouve la fonction permettant de calculer l'équation ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lien avec le principe MRE\n",
    "## Gradient de la fonction de coût\n",
    "\n",
    "### Fonction de coût:\n",
    "\n",
    "$$ \\hat{\\mathcal{L}}(\\textbf{w}) = \\frac{1}{m}\\sum_{t=1}^{m}\\ln{(1 + e^{-yh_w(x_i)})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le gradient de la fonction:\n",
    "\n",
    "$$ \\nabla \\hat{\\mathcal{L}}(\\textbf{w}) = \\frac{1}{m}\\sum_{t=1}^{m}y_i \\Big(1 - \\frac{1}{1 + e^{-y_ih_w(x_i)}}\\Big) \\times x_i $$\n",
    "\n",
    "- Pour l'apprentissage des paramètres du modèle de la régression logistique en utilisant la méthode du gradient conjugué  pour minimser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83803556, 0.61304288, 0.36449785, 0.98910345, 0.35957944,\n",
       "       0.53492331, 0.98187581, 0.88796381, 0.46098999, 0.72529755,\n",
       "       0.7147501 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.26578496, -56.46922877,   6.70250958,  34.3637157 ,\n",
       "       -16.71997027,   5.65836299,   4.6437897 ,  -5.20795306,\n",
       "         1.94802187, -26.01408182, -49.99999999])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = 2\n",
    "# w = np.random.random(d)\n",
    "lg.gradient_logistic_surrogate_loss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.26578496, -56.46922877,   6.70250958,  34.3637157 ,\n",
       "       -16.71997027,   5.65836299,   4.6437897 ,  -5.20795306,\n",
       "         1.94802187, -26.01408182, -49.99999999])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0 = 2\n",
    "# w = np.random.random(d)\n",
    "lg.gradient_logistic_surrogate_loss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(X.shape[1]+1)\n",
    "Lold = lg.logistic_surrogate_loss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25000000000011413"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5588818668>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = np.linspace(-100, 100, 101)\n",
    "plt.plot(x_test, lg.logistic(x_test))\n",
    "plt.plot(x_test, lg.stable_logistic(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1/(1+np.exp(-100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage des paramètres du modèle\n",
    "\n",
    "La régression linéaire utilise la méthode du gradient conjugué afin de minimiser la fonction de coût.\n",
    "\n",
    "Le gradient conjugué utilise lui-même une recherche linéaire afin de trouver le pas d'apprentissage optimal.\n",
    "Un brève présentation de l'algorithme de recherche linéaire s'impose donc.\n",
    "\n",
    "## recherche linéaire\n",
    "\n",
    "On cherche une valeur maximale admissible du pas d'apprentissage en allant selon un direction de descente $p_t$ (vérifiant $p_t^T\\nabla\\mathcal{L}(w)$.\n",
    "On suit toujours un règle de mise à jour avec la condition de décroissance de la fonction de coût.\n",
    "$$\\forall{t} \\in \\mathbb{N}, \\hat{\\mathcal{L}}(w^{(t+1)}) < \\hat{\\mathcal{L}}(w^{(t)}) $$\n",
    "\n",
    "L'algorithme de recherche linéaire consiste à vérifier des conditions que l'on appelle *conditions de Wolfe*.\n",
    "\n",
    "### Condition d'Armijo\n",
    "\n",
    "Permet de répondre aux deux situations où l'équation ci-dessus peut être satisfaite sans pour autant atteindre le minimiseur de $\\mathcal{L}$.\n",
    "\n",
    "$$\\forall{t} \\in \\mathbb{N}, \\hat{\\mathcal{L}}(w^{(t)} + \\eta_tp_t) \\leq \\hat{\\mathcal{L}}(w_t) + \\alpha\\eta_tp_t^{T}\\nabla\\hat{\\mathcal{L}}(w_t)$$\n",
    "\n",
    "la contrainte de décroissance linéaire implique que le taux de décroissance allant $\\hat{\\mathcal{L}}(w^t)$ à $\\hat{\\mathcal{L}}(w^{t+1})$ ne doit pas être plus grand que la descente pondéré par un coefficient alpha.\n",
    "\n",
    "### Condition de courbure\n",
    "\n",
    "Cette condition implique que la descente lors de l'itération suivante soit au moins égale à une fraction $\\beta \\in (\\alpha, 1)$. Donc:\n",
    "$$ \\forall{t} \\in \\mathbb{N}, p^T_t\\nabla\\hat{\\mathcal{L}}(w^{(t)} + \\eta_tp_t) \\geq \\beta p^T_t\\nabla\\hat{\\mathcal{L}}(w^{(t)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.arange(10)\n",
    "p = q + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[1] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lg.gradient_logistic_surrogate_loss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.2\n",
    "eta2 = 1\n",
    "a = np.array([[1/eta**2, 1/eta2**2], [-eta2/eta, eta/eta2]])\n",
    "z = np.array([1-2-6, 3-4-1]).reshape(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7, -2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-176.99999999999997"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a @ z).reshape(1, -1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = 1/(eta-eta2) * np.dot(a,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ab.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = ab[0][0], ab[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.random(d+1)\n",
    "w2 = np.random.random(d+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34904512, 0.16932186, 0.13374972, 0.81801601, 0.79385639,\n",
       "       0.64817946, 0.93864967, 0.31621847, 0.29473971, 0.43414522,\n",
       "       0.00516014])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25031353500134523"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.logistic_surrogate_loss(X, y, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lg.logistic_surrogate_loss(X, y, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(36)line_search()\n",
      "-> alpha = 1e-4\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(37)line_search()\n",
      "-> min_eta = 1e-7\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(39)line_search()\n",
      "-> n, d = X.shape\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(42)line_search()\n",
      "-> pente = p @ g\n",
      "(Pdb) n\n",
      "ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 11 is different from 10)\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(42)line_search()\n",
      "-> pente = p @ g\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(42)line_search()->None\n",
      "-> pente = p @ g\n",
      "(Pdb) n\n",
      "ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 11 is different from 10)\n",
      "> <ipython-input-28-fb6817f57490>(2)<module>()\n",
      "-> g=g, old_loss=loss, w_old=w2)\n",
      "(Pdb) n\n",
      "--Return--\n",
      "> <ipython-input-28-fb6817f57490>(2)<module>()->None\n",
      "-> g=g, old_loss=loss, w_old=w2)\n",
      "(Pdb) n\n",
      "ValueError: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 11 is different from 10)\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/virtualenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3291)run_code()\n",
      "-> exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/virtualenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3294)run_code()\n",
      "-> sys.excepthook = old_excepthook\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/virtualenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3295)run_code()\n",
      "-> except SystemExit as e:\n",
      "(Pdb) c\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 11 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fb6817f57490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m w2, test_new_loss = opt.line_search(X, y, cost_func=lg.logistic_surrogate_loss, p=p, \n\u001b[0;32m----> 2\u001b[0;31m                                     g=g, old_loss=loss, w_old=w2)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# w2, test_new_loss = line_search(X, y, w2, cost_func=logistic_surrogate_loss, p=p, g=g)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py\u001b[0m in \u001b[0;36mline_search\u001b[0;34m(X, y, cost_func, p, g, old_loss, w_old)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Calcul de la pente au point actuel (float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Définition de la valeur minimale tolérée de eta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 11 is different from 10)"
     ]
    }
   ],
   "source": [
    "w2, test_new_loss = opt.line_search(X, y, cost_func=lg.logistic_surrogate_loss, p=p, \n",
    "                                    g=g, old_loss=loss, w_old=w2)\n",
    "# w2, test_new_loss = line_search(X, y, w2, cost_func=logistic_surrogate_loss, p=p, g=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77084941, 0.51170377, 0.48691143, 0.59902129, 0.99471183,\n",
       "       0.61206021, 0.38004313, 0.72647739, 0.3834334 , 0.98672469,\n",
       "       0.66083577])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499999999645529"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.logistic_surrogate_loss(X, y, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6995819789587178"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.logistic_surrogate_loss(X, y, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(11)\n",
    "b = np.arange(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4270fb359cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "print(ps.T.shape, g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99999999999999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient conjugué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(130)conjugate_gradient()\n",
      "-> epoque = 0\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(131)conjugate_gradient()\n",
      "-> n, d = X.shape\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(132)conjugate_gradient()\n",
      "-> w_old = np.random.random(d+1)\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(135)conjugate_gradient()\n",
      "-> new_loss = cost_func(X, y, w)\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(136)conjugate_gradient()\n",
      "-> old_loss = new_loss + 2 * epsilon\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(137)conjugate_gradient()\n",
      "-> g = grd_func(X, y, w)\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(139)conjugate_gradient()\n",
      "-> p = -g\n",
      "(Pdb) print(g)\n",
      "[ 31.43962682   0.06276278   5.54213954  -5.75087006   1.85309174\n",
      "  -9.14239035   3.75536922 -35.84533628  -6.12016493 -21.55472194\n",
      " -47.90183445]\n",
      "(Pdb) print(p)\n",
      "*** NameError: name 'p' is not defined\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(140)conjugate_gradient()\n",
      "-> print(new_loss)\n",
      "(Pdb) n\n",
      "0.2709816555412725\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(142)conjugate_gradient()\n",
      "-> while np.abs(old_loss - new_loss) > np.abs(old_loss) * epsilon:\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(143)conjugate_gradient()\n",
      "-> old_loss = new_loss\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(144)conjugate_gradient()\n",
      "-> w, new_loss = line_search(X=X, y=y, w=w, cost_func=cost_func,\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(145)conjugate_gradient()\n",
      "-> p=p, g=g, old_loss=old_loss,\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(146)conjugate_gradient()\n",
      "-> new_loss=new_loss, w_old=w_old)\n",
      "(Pdb) n\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(36)line_search()\n",
      "-> alpha = 1e-4\n",
      "(Pdb) c\n",
      "0.25\n",
      "Epoque 0 and loss is: 0.25\n",
      "[-0.66040672  0.83106175 -0.07548299  0.35270637  0.54640131  0.42384557\n",
      "  0.82167585  2.09351085  0.64029927  1.1854789   2.9087172 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/logistic_regression.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(x) / (1. + np.exp(-x)),\n",
      "/home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/logistic_regression.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "opt.conjugate_gradient(X=X, y=y, w=w, \n",
    "                   cost_func=lg.logistic_surrogate_loss, \n",
    "                   grd_func=lg.gradient_logistic_surrogate_loss, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31.43962682,   0.06276278,   5.54213954,  -5.75087006,\n",
       "         1.85309174,  -9.14239035,   3.75536922, -35.84533628,\n",
       "        -6.12016493, -21.55472194, -47.90183445])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.gradient_logistic_surrogate_loss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-856545bcae88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mps\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "ps**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des algos sur un table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "breast_cancer = pd.read_csv('../../DB/breast-cancer-wisconsin.data', sep=',', header=None)\n",
    "breast_cancer.columns = ['col' + str(i) for i in range(len(breast_cancer.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer.drop('col6', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.iloc[:, 1:-1]\n",
    "y = breast_cancer.iloc[:, -1]\n",
    "y[y==2] = -1\n",
    "y[y==4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, \n",
    "                                                    test_size=.4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21390211, 0.61197772, 0.99420996, 0.03849535, 0.74187365,\n",
       "       0.81380815, 0.86046331, 0.36382311, 0.24262976])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.random(X.shape[1]+1)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(131)conjugate_gradient()\n",
      "-> epoque = 0\n",
      "(Pdb) c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/logistic_regression.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(x) / (1.0 + np.exp(-x)),\n",
      "/home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/logistic_regression.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34844868735083534\n",
      "> /home/iaamini/Documents/ML_practice/ML_fundamentals/ML_fundamentals/algorithms/optimizers.py(36)line_search()\n",
      "-> alpha = 1e-4\n",
      "(Pdb) c\n",
      "[-421.13048483 -185.17699511 -199.66373247 -189.81458539 -290.04887726\n",
      " -278.79262835 -171.51222662 -145.942052   -135.70490661]\n",
      "[-177.77731091  -78.07850458  -84.19366181  -79.82934308 -122.32859962\n",
      " -117.71187978  -72.20796585  -61.64890042  -56.89658338]\n",
      "[-77.3517843  -33.88174257 -36.54216638 -34.44129369 -53.11480251\n",
      " -51.23804366 -31.22767978 -26.86330875 -24.37443775]\n",
      "[-33.35423416 -14.51864518 -15.66551151 -14.55627992 -22.79146132\n",
      " -22.11511012 -13.2737566  -11.6233507  -10.1261208 ]\n",
      "[-14.27734516  -6.12300364  -6.61360689  -5.93434077  -9.64356985\n",
      "  -9.48770316  -5.48911862  -5.01546032  -3.9481959 ]\n",
      "[-5.99081775 -2.47614519 -2.68168403 -2.18918425 -3.9324519  -4.00267078\n",
      " -2.10766496 -2.14515664 -1.26465855]\n",
      "[-2.39249087 -0.89253988 -0.97429287 -0.56289417 -1.45246624 -1.62086011\n",
      " -0.63930856 -0.89876109 -0.09936408]\n",
      "[-0.82987392 -0.20484014 -0.23283762  0.14334196 -0.37550248 -0.58653003\n",
      " -0.00165704 -0.35749875  0.40667913]\n",
      "[-0.15129513  0.09379893  0.0891452   0.4500306   0.09217756 -0.137364\n",
      "  0.27524818 -0.1224513   0.62643241]\n",
      "[ 0.14330576  0.22345128  0.2289321   0.58317762  0.29521803  0.05763873\n",
      "  0.39546491 -0.02040686  0.72183696]\n",
      "[0.27124769 0.27975787 0.28964002 0.64100191 0.38339628 0.14232627\n",
      " 0.44767372 0.02390992 0.76327012]\n",
      "[0.32680689 0.30420919 0.31600263 0.66611229 0.42168797 0.17910211\n",
      " 0.47034557 0.04315462 0.7812626 ]\n",
      "[0.350934   0.31482741 0.32745084 0.67701672 0.4383165  0.19507237\n",
      " 0.48019103 0.05151182 0.789076  ]\n",
      "[0.3614114  0.31943846 0.33242232 0.68175205 0.44553758 0.20200758\n",
      " 0.4844665  0.055141   0.79246904]\n",
      "[0.3659613  0.32144084 0.33458123 0.68380841 0.44867339 0.20501926\n",
      " 0.48632316 0.056717   0.7939425 ]\n",
      "[0.36793713 0.3223104  0.33551875 0.68470141 0.45003515 0.20632711\n",
      " 0.48712944 0.0574014  0.79458236]\n",
      "[0.36879515 0.32268801 0.33592588 0.6850892  0.4506265  0.20689505\n",
      " 0.48747957 0.0576986  0.79486022]\n",
      "[0.36916776 0.32285199 0.33610268 0.6852576  0.4508833  0.20714169\n",
      " 0.48763161 0.05782766 0.79498089]\n",
      "[0.36932956 0.3229232  0.33617946 0.68533073 0.45099482 0.20724879\n",
      " 0.48769764 0.05788371 0.79503329]\n",
      "[0.36939983 0.32295412 0.3362128  0.68536248 0.45104325 0.2072953\n",
      " 0.48772631 0.05790805 0.79505604]\n",
      "[0.36943034 0.32296755 0.33622728 0.68537627 0.45106428 0.2073155\n",
      " 0.48773877 0.05791862 0.79506592]\n",
      "[0.36944359 0.32297338 0.33623356 0.68538226 0.45107341 0.20732427\n",
      " 0.48774417 0.05792321 0.79507021]\n",
      "[0.36944935 0.32297592 0.33623629 0.68538486 0.45107738 0.20732808\n",
      " 0.48774652 0.0579252  0.79507208]\n",
      "[0.36945185 0.32297702 0.33623748 0.68538599 0.4510791  0.20732973\n",
      " 0.48774754 0.05792607 0.79507289]\n",
      "[0.36945293 0.32297749 0.33623799 0.68538648 0.45107985 0.20733045\n",
      " 0.48774798 0.05792644 0.79507324]\n",
      "[0.3694534  0.3229777  0.33623822 0.6853867  0.45108017 0.20733076\n",
      " 0.48774818 0.05792661 0.79507339]\n",
      "[0.36945361 0.32297779 0.33623832 0.68538679 0.45108031 0.2073309\n",
      " 0.48774826 0.05792668 0.79507346]\n",
      "[0.3694537  0.32297783 0.33623836 0.68538683 0.45108037 0.20733096\n",
      " 0.48774829 0.05792671 0.79507349]\n",
      "0.34844868735083534\n",
      "Epoque 0 and loss is: 0.34844868735083534\n",
      "[0.36945376 0.32297786 0.33623839 0.68538686 0.45108042 0.207331\n",
      " 0.48774832 0.05792673 0.79507351]\n"
     ]
    }
   ],
   "source": [
    "w = opt.conjugate_gradient(X=X_train, y=y_train, w=w, \n",
    "                   cost_func=lg.logistic_surrogate_loss, \n",
    "                   grd_func=lg.gradient_logistic_surrogate_loss, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36945376, 0.32297786, 0.33623839, 0.68538686, 0.45108042,\n",
       "       0.207331  , 0.48774832, 0.05792673, 0.79507351])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
