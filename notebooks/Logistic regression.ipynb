{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return (1.0 / (1.0 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GradientLogisticSurrogateLoss0(X, y):\n",
    "#     n, d = X.shape\n",
    "#     w0 = 0.\n",
    "#     w = np.random.random(d)\n",
    "\n",
    "#     g0 = 0.\n",
    "#     g = np.zeros(d)\n",
    "#     ps = w0\n",
    "#     for i in range(n):\n",
    "#         for j in range(d):\n",
    "#             ps+=w[j] * X[i, j]\n",
    "#         g0 += (logistic(y[i]*ps)-1.0)*y[i]\n",
    "#         for j in range(d):\n",
    "#             g[j] += (logistic(y[i]*ps)-1.0)*y[i]*X[i, j]\n",
    "#     g/=n\n",
    "#     return g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape\n",
    "w0 = 0.\n",
    "w = np.random.random(d)\n",
    "\n",
    "g0 = 0.\n",
    "g = np.zeros(d)\n",
    "ps = w0\n",
    "for i in range(n):\n",
    "    for j in range(d):\n",
    "        ps+=w[j] * X[i, j]\n",
    "    g0 += (logistic(y[i]*ps)-1.0)*y[i]\n",
    "    for j in range(d):\n",
    "        g[j] += (logistic(y[i]*ps)-1.0)*y[i]*X[i, j]\n",
    "g/=n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10662097,  0.07604387,  0.04677539, -0.0520893 , -0.53722717,\n",
       "       -0.03842213,  0.09648553, -0.04118927,  0.03814647,  0.26124687])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.857930379149902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.857930379149948"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(w, X.T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99903745200187"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((logistic(y * ps) - 1.0)*y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99903745200187"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list(map(lambda x: (logistic(x * ps)-1.0)*x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-17ad5fc2cb67>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-17ad5fc2cb67>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test np.dot(y, ps)-1.0\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test np.dot(y, ps)-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.93778315, -8.93778315, -8.93778315, -8.93778315, -8.93778315,\n",
       "       -8.93778315, -6.42896519, -6.42896519, -8.93778315, -6.42896519,\n",
       "       -8.93778315, -6.42896519, -8.93778315, -6.42896519, -8.93778315,\n",
       "       -8.93778315, -8.93778315, -6.42896519, -6.42896519, -6.42896519,\n",
       "       -6.42896519, -6.42896519, -8.93778315, -8.93778315, -8.93778315,\n",
       "       -6.42896519, -6.42896519, -8.93778315, -6.42896519, -8.93778315,\n",
       "       -8.93778315, -6.42896519, -8.93778315, -6.42896519, -6.42896519,\n",
       "       -8.93778315, -8.93778315, -8.93778315, -6.42896519, -6.42896519,\n",
       "       -6.42896519, -8.93778315, -6.42896519, -6.42896519, -8.93778315,\n",
       "       -8.93778315, -6.42896519, -8.93778315, -6.42896519, -8.93778315,\n",
       "       -6.42896519, -6.42896519, -6.42896519, -8.93778315, -8.93778315,\n",
       "       -8.93778315, -8.93778315, -8.93778315, -8.93778315, -8.93778315,\n",
       "       -6.42896519, -6.42896519, -6.42896519, -6.42896519, -6.42896519,\n",
       "       -6.42896519, -8.93778315, -8.93778315, -8.93778315, -6.42896519,\n",
       "       -6.42896519, -6.42896519, -6.42896519, -8.93778315, -8.93778315,\n",
       "       -6.42896519, -8.93778315, -6.42896519, -6.42896519, -8.93778315,\n",
       "       -8.93778315, -8.93778315, -8.93778315, -6.42896519, -6.42896519,\n",
       "       -6.42896519, -6.42896519, -6.42896519, -6.42896519, -6.42896519,\n",
       "       -8.93778315, -6.42896519, -8.93778315, -8.93778315, -6.42896519,\n",
       "       -6.42896519, -8.93778315, -8.93778315, -6.42896519, -8.93778315])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logistic(y)*ps - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9999807490400375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(y[0]*ps)-1.0*y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99903745200187"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((logistic(y*ps)-1.0)*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-49.99903745200183\n"
     ]
    }
   ],
   "source": [
    "g0 = 0.\n",
    "for i in range(n):\n",
    "    g0 += (logistic(y[i]*ps)-1.0)*y[i]\n",
    "print(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99903745200183"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.zeros(d)\n",
    "for i in range(n):\n",
    "    for j in range(d):\n",
    "        g[j] += (logistic(y[i]*ps)-1.0)*y[i]*X[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1136041 ,  0.07665674,  0.03935434, -0.05335246, -0.54952494,\n",
       "       -0.03964456,  0.09230523, -0.03624674,  0.03698542,  0.26658827])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1136041 ,  0.07665674,  0.03935434, -0.05335246, -0.54952494,\n",
       "       -0.03964456,  0.09230523, -0.03624674,  0.03698542,  0.26658827])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((logistic(y*ps) - 1.0)*y) @ X)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Add weight vector as an argument to GradientLogisticSurrogateLoss and take into cosnideration the w0 case\n",
    "#TODO: \n",
    "def GradientLogisticSurrogateLoss(X, y, w):\n",
    "    \"\"\"Computes the gradient logistic surrogate loss\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: {array like, sparse matrix}, shape (n_samples, n_features)\n",
    "       Samples\n",
    "    y: array, shape (n_samples)\n",
    "       True labels\n",
    "    w: array, shape (n_features)\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    Surrogate loss gradient vector\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    w0 = 0.\n",
    "    g = np.zeros(d)\n",
    "    ps = np.dot(w, X.T).sum()\n",
    "    g0 = np.sum((logistic(y*ps)-1.0)*y)\n",
    "    g += ((logistic(y*ps) - 1.0)*y) @ X\n",
    "    g /= n\n",
    "    return g, g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(X.shape[1])\n",
    "g, g0 = GradientLogisticSurrogateLoss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-49.99958690630395"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: A revoir!\n",
    "def LogisticSurrogateLoss(X, y, w):\n",
    "    \"\"\"Computes the Logistic surrogate loss. Will be used for Logistic Regression\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    X: Array, shape (n_samples, n_features)\n",
    "       Samples...\n",
    "    y: array, shape (n_samples)\n",
    "       True labels\n",
    "    w: array shape (n_features,)\n",
    "       Weight vector\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    Float, logistic SurrogateLoss value\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    ps = np.dot(w, X.T)\n",
    "    S = (np.log(1.0 + np.exp(-y * ps))).sum()\n",
    "    S /= n\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(X.shape[1])\n",
    "Lold = LogisticSurrogateLoss(X, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=np.dot(w, X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23482869e+00, -3.20039796e+00,  4.63824493e-01,  3.27129363e+00,\n",
       "       -1.55908147e+00, -4.14920637e+00, -4.42205858e+00, -1.23031421e+00,\n",
       "        6.95481074e-01, -6.65694718e+00, -2.22797456e+00, -2.20180147e+00,\n",
       "       -5.70326212e-01,  5.88132165e-01,  1.69963729e+00,  1.17739070e+00,\n",
       "        2.58147492e+00,  7.10446577e-01, -3.86996930e-01,  4.36250305e+00,\n",
       "        1.47759233e-01, -2.25610677e+00, -2.34082976e+00, -5.54430289e-01,\n",
       "       -1.98715166e+00, -2.52919875e+00,  2.41915225e+00,  2.23108214e+00,\n",
       "        2.23924610e+00, -6.22688972e+00, -2.08294412e+00,  3.31005258e+00,\n",
       "       -4.04078524e-01, -1.88445229e+00,  2.62547626e+00,  1.91901494e-01,\n",
       "        9.23604093e-01,  3.31472886e-01, -6.76036614e-01,  2.31582258e+00,\n",
       "        8.10631549e-01, -5.50227861e+00, -4.49801112e+00, -9.78367552e-01,\n",
       "        1.67281715e+00, -6.48333563e+00,  2.37149933e+00,  5.07835940e+00,\n",
       "       -1.66785162e+00,  3.16027051e+00, -8.76249329e-01, -3.03560908e+00,\n",
       "       -2.20087759e+00,  2.28011250e-03, -6.18615383e+00,  9.12187738e-01,\n",
       "       -2.00771233e+00, -6.33805219e-01,  2.30349910e+00,  3.76640190e-01,\n",
       "        2.71960200e+00,  3.05448962e+00, -1.48588525e+00, -4.08027013e+00,\n",
       "        2.33743482e+00, -1.12178135e+00,  1.98915757e+00, -3.47500451e-01,\n",
       "       -8.40929514e-01, -1.98434338e+00, -3.26581828e+00,  3.67744352e+00,\n",
       "       -1.66194912e+00,  8.84252478e-02, -2.61575529e-01, -4.36780637e+00,\n",
       "        2.99860843e+00, -1.00468341e+00, -9.76572489e-01,  1.32765167e+00,\n",
       "        3.24715622e+00,  4.34478479e+00, -8.42179177e-01, -4.47393836e-01,\n",
       "        4.26792302e+00,  1.72746607e+00,  1.19382286e-01, -9.67013262e-01,\n",
       "       -3.38428257e-01,  2.53221481e+00,  1.91764172e+00,  2.23841543e+00,\n",
       "        1.88608726e+00,  2.41333388e+00,  1.58492822e+00,  3.75883212e+00,\n",
       "       -3.94202963e+00, -2.18147866e+00,  2.53133712e+00, -1.79507849e+00])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0236582329815263"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1.0 + np.exp(-y*ps)).sum() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79128792, 0.82932286, 0.99046329, 0.10986741, 0.71671955,\n",
       "       0.87780234, 0.54146582, 0.43204759, 0.86587738, 0.95199199])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line search\n",
    "\n",
    "Before coding the conjugate gradient descent we have to code the line search which is used to optimize the learning step $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(11)\n",
    "b = np.arange(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: A quelle valeurs sont initialisées eta et eta2 ?\n",
    "def line_search(X, y, w, cost_func, grd, wnew, Lold, g, g0, p, p0, L):\n",
    "    \"\"\"Computing line search algorithm\n",
    "    Parameters\n",
    "    -----------\n",
    "    cost_func : function, \n",
    "            Cost function to minimize\n",
    "    grd : function\n",
    "        Gradient of cost function\n",
    "    Lold : float,\n",
    "        Vector of current loss \n",
    "    g : array \n",
    "        Vector of gradient\n",
    "    p : array \n",
    "        Descent direction\n",
    "    w : array \n",
    "        New weight vectors\n",
    "    L: float \n",
    "        New loss value\n",
    "    \"\"\"\n",
    "    print(L)\n",
    "    _alpha = 1e-4\n",
    "    _mineta = 1e-7\n",
    "    m, d = X.shape\n",
    "    pente = 0.\n",
    "    # Computing the value of the slope\n",
    "    pente = np.sum(p+g)\n",
    "    \n",
    "    # Defining minimal tolerated value of eta\n",
    "    _max = 0.\n",
    "    for j in range(d):\n",
    "        print(np.abs(p[j]))\n",
    "        print(np.abs(p[j]) > _max  * np.maximum(np.abs(w[0]), 1))\n",
    "        if np.abs(p[j]) > _max  * np.maximum(np.abs(w[0]), 1):\n",
    "            _max = np.maximum(np.abs(w[j]), 1.0)\n",
    "    etamin = _mineta / _max\n",
    "    \n",
    "    ## Mise à jour du vecteur poids pour la plus grande valeur de eta\n",
    "    ## à partir de laquelle on commence la recherche\n",
    "    eta = 1.0\n",
    "    wnew = w + (eta*p)\n",
    "    \n",
    "    L = cost_func(X, y, wnew)\n",
    "    \n",
    "    # Boucler tant que la condition d'Armijo n'est pas satisfaite (Eq. 2.18)\n",
    "    while L > (Lold +_alpha*eta*pente):\n",
    "        if eta < etamin:\n",
    "            wnew = w\n",
    "            break\n",
    "        else:\n",
    "            if eta == 1.0:\n",
    "                etatmp = -pente/(2.0*(L-Lold-pente))\n",
    "            else:\n",
    "                coeff1 = L - Lold - eta*pente\n",
    "                coeff2 = L - Lold - eta*pente\n",
    "                # Calcul des coefficients du polynôme d'interpolation de degré 3 (Eq 2.33)\n",
    "                a = (coeff1/(eta**2) - coeff2/(eta2**2)) / (eta-eta2)\n",
    "                if a != 0.:\n",
    "                    _delta = np.abs(((b**2)-3.0*a*pente).sum())\n",
    "                    print(\"This is delta!\")\n",
    "                    print(_delta)\n",
    "                    if _delta >= 0.:\n",
    "                        # Le minimiseur du polynôme d'interpolationi de degré 3 (Eq. 2.34)\n",
    "                        etatmp = ((-b+np.sqrt(_delta))/(3.*a)).sum()\n",
    "                    else:\n",
    "                        raise ValueError(\"rchln : problème d'interpolation\")\n",
    "                else:\n",
    "                    etatmp = -pente/(2.0*b)\n",
    "                    \n",
    "                if etatmp > 0.5*eta:\n",
    "                    etatmp = 0.5*eta\n",
    "                    \n",
    "        eta2 = eta\n",
    "        L2 = L\n",
    "        eta = np.maximum(etatmp, 0.1*eta)\n",
    "        wnew = w + eta*p\n",
    "        L = cost_func(X, y, wnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0236582329815263"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9443807802857705\n",
      "0.11360534351674163\n",
      "True\n",
      "0.07665757803728368\n",
      "False\n",
      "0.03935476796972177\n",
      "False\n",
      "0.05335304807304867\n",
      "False\n",
      "0.5495309774287122\n",
      "False\n",
      "0.03964499717721568\n",
      "False\n",
      "0.09230624935617487\n",
      "False\n",
      "0.036247136591752556\n",
      "False\n",
      "0.036985826057403054\n",
      "False\n",
      "0.2665911997507499\n",
      "False\n",
      "This is delta!\n",
      "352.1461103960643\n",
      "This is delta!\n",
      "18583.534431925065\n",
      "This is delta!\n",
      "18169853.797094148\n",
      "This is delta!\n",
      "18090534055.19902\n",
      "This is delta!\n",
      "18082565256190.383\n",
      "This is delta!\n",
      "1.808176835073327e+16\n",
      "This is delta!\n",
      "1.8081688660274715e+19\n"
     ]
    }
   ],
   "source": [
    "w_new = np.random.random(X.shape[1])\n",
    "Lold = LogisticSurrogateLoss(X, y, w_new)\n",
    "p0, p = g0, g\n",
    "\n",
    "line_search(X, y, w, LogisticSurrogateLoss, g, w, Lold, g, g0, p, p0, Lold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_max = 0.\n",
    "p[0] > _max  * np.maximum(np.abs(w[0]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(X, y, w, cost_func, grd_func, eps=0.1):\n",
    "    # Random initialization of weights\n",
    "    m, d = X.shape\n",
    "    w = np.random.random(d)\n",
    "    \n",
    "    # Initializing losses\n",
    "    L = cost_func(X, y, w)\n",
    "    Lold = L + 2*eps\n",
    "    g, g0 = grd_func(X, y, w)\n",
    "    p, p0 = -g, -g0\n",
    "    t = 0\n",
    "#     line_search(X, y, w, cost_func, g, w, Lold, g, g0, p, p0, L)\n",
    "    while np.abs(Lold - L) > (np.abs(Lold) * eps):\n",
    "        \n",
    "       \n",
    "        line_search(X, y, w, cost_func, g, w, Lold, g, g0, p, p0, L)\n",
    "        # line search is supposed to modify the values of w ou initialiser.\n",
    "        # creating new gradient vector h\n",
    "#         h = np.gradient(cost_func(X, y, w))\n",
    "        h, h0 = grd_func(X, y, w)\n",
    "        dgg = np.linalg.norm(g)\n",
    "        ngg = np.linalg.norm(h)\n",
    "        beta = dgg / ngg # Formule de Fletcher-Reeves (Eq 2.53)\n",
    "        wold = w\n",
    "        g = h\n",
    "        h0 = g0\n",
    "        p = -g + beta*p # MAJ de la direction de descente (Eq 2.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjugate_gradient(X, y, w, LogisticSurrogateLoss, GradientLogisticSurrogateLoss, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.52480188e+00, 1.02425471e+01, 2.15133161e-01, 1.07013620e+01,\n",
       "       2.43073503e+00, 1.72159135e+01, 1.95546021e+01, 1.51367305e+00,\n",
       "       4.83693924e-01, 4.43149458e+01, 4.96387063e+00, 4.84792972e+00,\n",
       "       3.25271988e-01, 3.45899443e-01, 2.88876691e+00, 1.38624886e+00,\n",
       "       6.66401277e+00, 5.04734339e-01, 1.49766624e-01, 1.90314329e+01,\n",
       "       2.18327910e-02, 5.09001778e+00, 5.47948398e+00, 3.07392945e-01,\n",
       "       3.94877172e+00, 6.39684630e+00, 5.85229759e+00, 4.97772750e+00,\n",
       "       5.01422311e+00, 3.87741556e+01, 4.33865622e+00, 1.09564480e+01,\n",
       "       1.63279453e-01, 3.55116045e+00, 6.89312559e+00, 3.68261833e-02,\n",
       "       8.53044520e-01, 1.09874274e-01, 4.57025503e-01, 5.36303424e+00,\n",
       "       6.57123508e-01, 3.02750699e+01, 2.02321041e+01, 9.57203067e-01,\n",
       "       2.79831721e+00, 4.20336409e+01, 5.62400909e+00, 2.57897342e+01,\n",
       "       2.78172902e+00, 9.98730968e+00, 7.67812886e-01, 9.21492248e+00,\n",
       "       4.84386218e+00, 5.19891299e-06, 3.82684992e+01, 8.32086469e-01,\n",
       "       4.03090879e+00, 4.01709055e-01, 5.30610811e+00, 1.41857833e-01,\n",
       "       7.39623501e+00, 9.32990682e+00, 2.20785496e+00, 1.66486044e+01,\n",
       "       5.46360154e+00, 1.25839340e+00, 3.95674784e+00, 1.20756563e-01,\n",
       "       7.07162448e-01, 3.93761865e+00, 1.06655690e+01, 1.35235908e+01,\n",
       "       2.76207488e+00, 7.81902446e-03, 6.84217572e-02, 1.90777325e+01,\n",
       "       8.99165252e+00, 1.00938874e+00, 9.53693827e-01, 1.76265895e+00,\n",
       "       1.05440235e+01, 1.88771549e+01, 7.09265766e-01, 2.00161244e-01,\n",
       "       1.82151669e+01, 2.98413901e+00, 1.42521303e-02, 9.35114648e-01,\n",
       "       1.14533685e-01, 6.41211183e+00, 3.67734978e+00, 5.01050365e+00,\n",
       "       3.55732514e+00, 5.82418041e+00, 2.51199747e+00, 1.41288189e+01,\n",
       "       1.55395976e+01, 4.75884915e+00, 6.40766762e+00, 3.22230678e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_gradient(X, y, cost_func, grd_func, epsilon=0.1):\n",
    "    # Initialisation des poids w\n",
    "    n, d = X.shape\n",
    "    w = np.random.random(d)\n",
    "    loss = cost_func(X, y, w)\n",
    "    old_loss = loss\n",
    "    p0 = grd_func(loss)\n",
    "    t = 0\n",
    "    while np.abs(loss - old_loss) <= epsilon * old_loss:\n",
    "        eta = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
