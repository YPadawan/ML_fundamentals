{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import line_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line search: what's in a name ?\n",
    "\n",
    "The line search is an algorithm allowing to find the optimal step size when minimizing a convex function.\n",
    "\n",
    "The main objective of the line search algorithm is to verify two conditions\n",
    "- Verifying Wolfe's conditions\n",
    "    - Armijo rule or sufficent decrease condition: It consists of making sure that the decrease of $f$ based on $\\alpha_k$.\n",
    "    $$\n",
    "    f(x + \\alpha_k p_k) \\leq f(x_k) + c_1\\alpha \\nabla f^{T}_k p_k\n",
    "    $$\n",
    "    - Curvature condition:\n",
    "    $$\n",
    "    \\nabla f(x_k + \\alpha_k p_k)^{T}p_k \\geq c_2\\nabla f^{T}_k p_k\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def back_tracking_ls(x0, f, g, p, alpha0=1, rho=1, c=1e-4):\n",
    "    alpha = alpha0\n",
    "    xk = x0\n",
    "    old_fval = f(xk)\n",
    "    while f(xk + alpha * p) > f(xk) + c*alpha*np.dot(g(xk).T, p):\n",
    "        alpha = rho*alpha\n",
    "    new_fval = f(xk + alpha * p)\n",
    "    return alpha, old_fval, new_fval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6.13, 1.1300000000000001)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    return (x[0])**2+(x[1])**2\n",
    "\n",
    "def g_square(x):\n",
    "    return np.array([2*x[0], 2*x[1]])\n",
    "\n",
    "x0 = np.array([1.8, 1.7])\n",
    "back_tracking_ls(x0, square, g_square, p=np.array([-1., -1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([-1, -1])\n",
    "alpha, fc, gc, new_loss, old_loss, new_slope = line_search(f=square, \n",
    "                                                           myfprime=g_square,\n",
    "                                                           xk=x0, pk=p, c1=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2\n",
      "1\n",
      "1.1300000000000001\n",
      "6.13\n",
      "[1.6, 1.4]\n"
     ]
    }
   ],
   "source": [
    "print(alpha)\n",
    "print(fc)\n",
    "print(gc)\n",
    "print(new_loss)\n",
    "print(old_loss)\n",
    "print(new_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of the line search algorithm and comparison with scipy's line search \n",
    "# result for rosenbrock function\n",
    "\n",
    "def rosenbrock(x):\n",
    "    y = np.asarray(x)\n",
    "    return np.sum((y[0] - 1)**2 + 100*(y[1] - y[0]**2)**2)\n",
    "\n",
    "def rosenbrock_grad(x):\n",
    "    y = np.asarray(x)\n",
    "    grad = np.zeros_like(y)\n",
    "    grad[0] = 400*y[0]*(y[0]**2-y[1]) + 2*(y[0]-1)\n",
    "    grad[1] = 200*(y[1]-y[0]**2)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19.399999999999995, 0.7999999999999999)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_tracking_ls(f=rosenbrock, g=rosenbrock_grad, alpha0=1, x0=np.array([1.2, 1]).T, p=np.array([-1., -1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, fc, gc, new_loss, old_loss, new_slope = line_search(f=rosenbrock, \n",
    "                                                           myfprime=rosenbrock_grad,\n",
    "                                                           xk=np.array([1.2, 1]).T, pk=p, c1=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 19.399999999999995 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(alpha, old_loss, new_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1.1,2.1])\n",
    "f0 = rosenbrock(x0)\n",
    "g0 = rosenbrock_grad(x0)\n",
    "p = -g0\n",
    "\n",
    "alpha, fc, gc, new_loss, old_loss, new_slope = line_search(f=rosenbrock, \n",
    "                                                           myfprime=rosenbrock_grad,\n",
    "                                                           xk=x0,pk=p, gfk=g0, old_fval=f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008127949077501714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
